{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q - Learning for the TSP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from src import model, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'njit',\n",
       " 'np',\n",
       " 'plt',\n",
       " 'route_distance',\n",
       " 'trace_progress']"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "dir(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'njit',\n",
       " 'np']"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix_15 = np.loadtxt(\"data/tsp_15_291.txt\") #15 cities and min cost = 291\n",
    "dist_matrix_26 = np.loadtxt(\"data/tsp_26_937.txt\")\n",
    "dist_matrix_17 = np.loadtxt(\"data/tsp_17_2085.txt\")\n",
    "dist_matrix_42 = np.loadtxt(\"data/tsp_42_699.txt\")\n",
    "dist_matrix_48 = np.loadtxt(\"data/tsp_48_33523.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'src.model' has no attribute 'QLearning'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-50c5b499f603>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mQ_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model.QLearning(Q_table,\n\u001b[0m\u001b[1;32m      3\u001b[0m               \u001b[0mdist_matrix_15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0;36m0.88\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'src.model' has no attribute 'QLearning'"
     ]
    }
   ],
   "source": [
    "Q_table = np.zeros((15,15))\n",
    "model.QLearning(Q_table,\n",
    "              dist_matrix_15,\n",
    "              1, \n",
    "              0.88, \n",
    "              0.1, \n",
    "              0.0001, \n",
    "              epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearnTSP:\n",
    "    def __init__(self, dist):\n",
    "        self.len_path = dist.shape[0]\n",
    "        self.dist = dist\n",
    "        #reward matrix, and Q matrix under the form of dictionnaries\n",
    "        #--------- should be optimized --------- #\n",
    "        start = 0 \n",
    "        end = 0 \n",
    "        rewards = {}\n",
    "        q = {}\n",
    "        states = [\"start\"] + [i for i in range(1, self.len_path)] + [\"end\"]\n",
    "        for s in states:\n",
    "            for n in states:\n",
    "                if s == n: \n",
    "                    q[(s,n)] = -np.inf\n",
    "                    continue\n",
    "                q[(s,n)]=0\n",
    "                s_i, n_i = s, n\n",
    "                if type(s) == str:\n",
    "                    s_i = 0\n",
    "                if type(n) == str:\n",
    "                    n_i = 0\n",
    "                if s_i == n_i: \n",
    "                    continue    \n",
    "\n",
    "                rewards[(s_i, n_i)] = -dist[s_i, n_i]\n",
    "                if n_i == 0:\n",
    "                    rewards[(s_i, n_i)] = 100 - dist[s_i, n_i]  \n",
    "        self.rewards = rewards\n",
    "        self.q = q\n",
    "    \n",
    "    \n",
    "\n",
    "    def follow_path(self, q_temp):\n",
    "        path = ['start']\n",
    "        while 'end' not in path:\n",
    "            possible_next = set([i for i in range(1, self.len_path)]) - set(path)\n",
    "            if possible_next == set():\n",
    "                path.append('end')\n",
    "                continue\n",
    "            next_state = list(possible_next)[0]\n",
    "            r = q_temp[(path[-1], next_state)]\n",
    "            for ele in possible_next:\n",
    "                if q_temp[(path[-1], ele)] > r:\n",
    "                    next_state = ele\n",
    "                    r = q_temp[(path[-1], ele)]\n",
    "            path.append(next_state)\n",
    "        return [0 if x in ['start', 'end'] else x for x in path]\n",
    "\n",
    "    \n",
    "    \n",
    "    def get_cost(self, path):\n",
    "        c = 0\n",
    "        for i in range(1, len(path)):\n",
    "            c += self.dist[path[i-1], path[i]]\n",
    "        return c\n",
    "\n",
    "    def qlearning(self, epsilon, gamma, lr, lbda, epochs = 100):\n",
    "        start = 0\n",
    "        eps = epsilon\n",
    "        q_learn = self.q.copy()\n",
    "        for t in range(epochs):\n",
    "            if t%(epochs/10) == 0:\n",
    "                print(\"Iteration :\", t, \"||\", \"epsilon = \", round(eps * (1-lbda), 2), \"||\", \"Current cost :\", self.get_cost(self.follow_path(q_learn)))\n",
    "\n",
    "            current_state = start\n",
    "            current_path = [start]\n",
    "            eps = eps * (1-lbda)\n",
    "            while len(current_path) < self.len_path+1:\n",
    "                if len(current_path) == self.len_path:\n",
    "                    current_path.append(0)\n",
    "                    #do \n",
    "\n",
    "                    #\n",
    "                    continue\n",
    "                current_state = current_path[-1]\n",
    "                possible_next = set([i for i in range(1, self.len_path)]) - set(current_path)\n",
    "                u = np.random.random()\n",
    "                if u < eps:\n",
    "                    next_state = np.random.choice(list(possible_next))\n",
    "                else:\n",
    "                    key_next = [(current_state, n) for n in possible_next]\n",
    "                    next_state = list(possible_next)[0]\n",
    "                    r = self.rewards[(current_state, next_state)]\n",
    "                    for e in key_next:\n",
    "                        if self.rewards[e] > r:\n",
    "                            next_state = e[1]\n",
    "                            r = self.rewards[e]\n",
    "                current_path.append(next_state)\n",
    "                #updating Q\n",
    "                c_s, n_s, c_s_i, n_s_i = current_state, next_state, current_state, next_state\n",
    "                if current_state == 0:\n",
    "                    c_s_i = 'start'\n",
    "                if next_state == 0:\n",
    "                    n_s_i = 'end'\n",
    "                possible_next = set([i for i in range(1, self.len_path)]) - set(current_path) - set([next_state])\n",
    "                if possible_next == set():\n",
    "                    continue\n",
    "\n",
    "                max_r_n = list(possible_next)[0]\n",
    "                m_r = q_learn[(c_s_i, n_s_i)]\n",
    "                for ele in possible_next.union(set([\"end\"])):\n",
    "                    if q_learn[(c_s_i, ele)] > m_r:\n",
    "                        max_r_n = ele\n",
    "                        m_r = q_learn[(c_s_i, ele)] \n",
    "\n",
    "                q_learn[(c_s_i, n_s_i)] = q_learn[(c_s_i, n_s_i)] + lr * ((self.rewards[(c_s, n_s)] + gamma * m_r - q_learn[(c_s_i, n_s_i)]))\n",
    "        return q_learn\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix_15 = np.loadtxt(\"data/tsp_15_291.txt\") #15 cities and min cost = 291\n",
    "dist_matrix_26 = np.loadtxt(\"data/tsp_26_937.txt\")\n",
    "dist_matrix_17 = np.loadtxt(\"data/tsp_17_2085.txt\")\n",
    "dist_matrix_42 = np.loadtxt(\"data/tsp_42_699.txt\")\n",
    "dist_matrix_48 = np.loadtxt(\"data/tsp_48_33523.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = QLearnTSP(dist_matrix_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 0 || epsilon =  1.0 || Current cost : 817.0\n",
      "Iteration : 400 || epsilon =  0.96 || Current cost : 291.0\n",
      "Iteration : 800 || epsilon =  0.92 || Current cost : 291.0\n",
      "Iteration : 1200 || epsilon =  0.89 || Current cost : 291.0\n",
      "Iteration : 1600 || epsilon =  0.85 || Current cost : 291.0\n",
      "Iteration : 2000 || epsilon =  0.82 || Current cost : 291.0\n",
      "Iteration : 2400 || epsilon =  0.79 || Current cost : 291.0\n",
      "Iteration : 2800 || epsilon =  0.76 || Current cost : 291.0\n",
      "Iteration : 3200 || epsilon =  0.73 || Current cost : 291.0\n",
      "Iteration : 3600 || epsilon =  0.7 || Current cost : 291.0\n",
      "Wall time: 1.86 s\n"
     ]
    }
   ],
   "source": [
    "%time Q_15 = solver.qlearning(1, 0.88, 0.1, 0.0001, 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = QLearnTSP(dist_matrix_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 0 || epsilon =  1.0 || Current cost : 4517.0\n",
      "Iteration : 1000 || epsilon =  0.9 || Current cost : 2199.0\n",
      "Iteration : 2000 || epsilon =  0.82 || Current cost : 2199.0\n",
      "Iteration : 3000 || epsilon =  0.74 || Current cost : 2199.0\n",
      "Iteration : 4000 || epsilon =  0.67 || Current cost : 2187.0\n",
      "Iteration : 5000 || epsilon =  0.61 || Current cost : 2187.0\n",
      "Iteration : 6000 || epsilon =  0.55 || Current cost : 2187.0\n",
      "Iteration : 7000 || epsilon =  0.5 || Current cost : 2187.0\n",
      "Iteration : 8000 || epsilon =  0.45 || Current cost : 2187.0\n",
      "Iteration : 9000 || epsilon =  0.41 || Current cost : 2187.0\n",
      "Wall time: 5.1 s\n"
     ]
    }
   ],
   "source": [
    "%time Q_17 = solver.qlearning(1, 0.88, 0.1, 0.0001, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = QLearnTSP(dist_matrix_26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 0 || epsilon =  1.0 || Current cost : 1159.0\n",
      "Iteration : 1000 || epsilon =  0.37 || Current cost : 1050.0\n",
      "Iteration : 2000 || epsilon =  0.14 || Current cost : 1050.0\n",
      "Iteration : 3000 || epsilon =  0.05 || Current cost : 1050.0\n",
      "Iteration : 4000 || epsilon =  0.02 || Current cost : 1050.0\n",
      "Iteration : 5000 || epsilon =  0.01 || Current cost : 1050.0\n",
      "Iteration : 6000 || epsilon =  0.0 || Current cost : 1050.0\n",
      "Iteration : 7000 || epsilon =  0.0 || Current cost : 1050.0\n",
      "Iteration : 8000 || epsilon =  0.0 || Current cost : 1050.0\n",
      "Iteration : 9000 || epsilon =  0.0 || Current cost : 1050.0\n",
      "Wall time: 5.76 s\n"
     ]
    }
   ],
   "source": [
    "%time Q_26 = solver.qlearning(1, 0.88, 0.2, 0.001, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = QLearnTSP(dist_matrix_42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 0 || epsilon =  1.0 || Current cost : 962.0\n",
      "Iteration : 1000 || epsilon =  0.9 || Current cost : 916.0\n",
      "Iteration : 2000 || epsilon =  0.82 || Current cost : 955.0\n",
      "Iteration : 3000 || epsilon =  0.74 || Current cost : 955.0\n",
      "Iteration : 4000 || epsilon =  0.67 || Current cost : 955.0\n",
      "Iteration : 5000 || epsilon =  0.61 || Current cost : 955.0\n",
      "Iteration : 6000 || epsilon =  0.55 || Current cost : 955.0\n",
      "Iteration : 7000 || epsilon =  0.5 || Current cost : 955.0\n",
      "Iteration : 8000 || epsilon =  0.45 || Current cost : 955.0\n",
      "Iteration : 9000 || epsilon =  0.41 || Current cost : 955.0\n",
      "Wall time: 19.1 s\n"
     ]
    }
   ],
   "source": [
    "%time Q_42 = solver.qlearning(1, 0.8, 0.1, 0.0001, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = QLearnTSP(dist_matrix_48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 0 || epsilon =  1.0 || Current cost : 151722.0\n",
      "Iteration : 400 || epsilon =  0.96 || Current cost : 59238.0\n",
      "Iteration : 800 || epsilon =  0.92 || Current cost : 41452.0\n",
      "Iteration : 1200 || epsilon =  0.89 || Current cost : 38970.0\n",
      "Iteration : 1600 || epsilon =  0.85 || Current cost : 40610.0\n",
      "Iteration : 2000 || epsilon =  0.82 || Current cost : 40551.0\n",
      "Iteration : 2400 || epsilon =  0.79 || Current cost : 40551.0\n",
      "Iteration : 2800 || epsilon =  0.76 || Current cost : 40610.0\n",
      "Iteration : 3200 || epsilon =  0.73 || Current cost : 40551.0\n",
      "Iteration : 3600 || epsilon =  0.7 || Current cost : 40551.0\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%time Q_48 = solver.qlearning(1, 0.8, 0.1, 0.0001, 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}